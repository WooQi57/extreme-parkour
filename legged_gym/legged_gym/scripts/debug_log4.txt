load 100-27

********************************************************************************
Loading model from /iris/u/wuqi23/doggybot/extreme-parkour/legged_gym/logs/parkour_new/100-27-cam2ac/model_18000.pt...
Saved depth encoder detected, loading...
Saved depth actor detected, loading...
********************************************************************************
Layer: priv_encoder.0.weight 
Shape: torch.Size([64, 33]) 
Values: tensor([[ 0.0710, -0.1824, -1.3241,  ...,  0.0088, -0.0554,  0.2342],
        [-0.0033,  0.2324,  0.1403,  ...,  0.2027,  0.2281,  0.0898],
        [ 0.0448,  0.0470,  1.3082,  ..., -0.1515,  0.2367, -0.2161],
        ...,
        [-0.0131,  0.1512,  1.1946,  ...,  0.0087, -0.2233, -0.2720],
        [ 0.0118,  0.3774, -0.6024,  ...,  0.1086, -0.0479,  0.2261],
        [ 0.0256, -0.3420, -0.5530,  ...,  0.3324,  0.1579, -0.0137]],
       device='cuda:0')

Layer: priv_encoder.0.bias 
Shape: torch.Size([64]) 
Values: tensor([ 0.1254,  0.0213,  0.0387, -0.0842,  0.0684, -0.1625, -0.0953,  0.1210,
        -0.3156, -0.3277, -0.0635,  0.2483,  0.4391,  0.1501,  0.1902, -0.3369,
        -0.2585,  0.0384,  0.0805,  0.0024, -0.2306, -0.1119, -0.1439,  0.1109,
        -0.1948, -0.0826,  0.0946, -0.0433, -0.0684, -0.2311,  0.1359,  0.4654,
         0.2494,  0.1283, -0.3071,  0.0023, -0.2631, -0.0390,  0.0931,  0.2156,
        -0.1964, -0.0488,  0.1875,  0.0119,  0.1219,  0.0725,  0.0398,  0.2525,
         0.3993, -0.0764,  0.2155,  0.0821, -0.1172, -0.0735, -0.1068,  0.1589,
         0.2772,  0.1772,  0.1692,  0.1143,  0.1386,  0.0829, -0.3185,  0.0797],
       device='cuda:0')

Layer: priv_encoder.2.weight 
Shape: torch.Size([20, 64]) 
Values: tensor([[-0.0452, -0.0444,  0.0117,  ..., -0.0344,  0.0170,  0.0355],
        [-0.0222, -0.0135,  0.0340,  ...,  0.0502, -0.0313,  0.0165],
        [ 0.1235,  0.0430, -0.1144,  ..., -0.1439,  0.1328, -0.0332],
        ...,
        [-0.0300, -0.0833, -0.0019,  ..., -0.0354,  0.0637,  0.0318],
        [ 0.0281, -0.0384, -0.0733,  ..., -0.0348,  0.0742, -0.0205],
        [-0.0644,  0.0023, -0.0218,  ..., -0.0694,  0.0630, -0.0245]],
       device='cuda:0')

Layer: priv_encoder.2.bias 
Shape: torch.Size([20]) 
Values: tensor([-0.0720, -0.0149, -0.0843, -0.0877, -0.0801, -0.1007, -0.0413,  0.1828,
        -0.0531, -0.0810, -0.0736, -0.0345, -0.1010, -0.0341,  0.0192, -0.0359,
        -0.0670, -0.0006, -0.0500, -0.0444], device='cuda:0')

Layer: history_encoder.encoder.0.weight 
Shape: torch.Size([30, 55]) 
Values: tensor([[ 0.0806,  0.0949, -0.5754,  ...,  0.0105,  0.0069, -0.0200],
        [-0.0818, -0.3483, -0.3385,  ..., -0.0192,  0.0074,  0.0578],
        [ 0.2058, -0.6192,  0.1485,  ...,  0.1339,  0.0726, -0.1256],
        ...,
        [ 0.1904,  0.6844,  0.0273,  ...,  0.0187,  0.1128,  0.0351],
        [ 0.1069,  0.1394, -0.2687,  ..., -0.0763,  0.0859, -0.0646],
        [-0.1504,  0.5526, -0.4109,  ..., -0.1145,  0.1172, -0.0732]],
       device='cuda:0')

Layer: history_encoder.encoder.0.bias 
Shape: torch.Size([30]) 
Values: tensor([-0.2722,  0.0933, -0.2357, -0.0145,  0.0206,  0.0289,  0.0536, -0.0937,
        -0.1845,  0.0709,  0.1401,  0.1932,  0.0391, -0.2427,  0.0204, -0.1298,
        -0.1318, -0.0050, -0.1291,  0.1241,  0.1132,  0.1549, -0.0260,  0.0505,
        -0.0384, -0.2143, -0.0721, -0.1312,  0.0301,  0.0707], device='cuda:0')

Layer: history_encoder.conv_layers.0.weight 
Shape: torch.Size([20, 30, 4]) 
Values: tensor([[[ 0.1523,  0.0604,  0.0159,  0.0458],
         [-0.0691, -0.0924, -0.1359, -0.1458],
         [-0.0782, -0.0439,  0.0599,  0.1272],
         ...,
         [ 0.1400,  0.1380,  0.0330,  0.0788],
         [-0.0934, -0.1022,  0.0435, -0.0027],
         [-0.0621, -0.0675, -0.0513, -0.0707]],

        [[ 0.0167, -0.0394, -0.0518, -0.0988],
         [-0.0100, -0.1090, -0.0718, -0.1231],
         [ 0.1415,  0.0165,  0.0058,  0.0893],
         ...,
         [ 0.1316,  0.0921,  0.0184,  0.1471],
         [ 0.0961,  0.0680,  0.1028,  0.1367],
         [-0.1018, -0.0784, -0.0960, -0.1190]],

        [[ 0.1325,  0.1900,  0.1955,  0.0866],
         [-0.3147, -0.2231, -0.0740, -0.1046],
         [ 0.0834,  0.1367,  0.1703,  0.2907],
         ...,
         [ 0.0226,  0.1132,  0.0733,  0.1184],
         [-0.0318,  0.0088, -0.0813, -0.0092],
         [-0.2387, -0.2582, -0.2888, -0.4178]],

        ...,

        [[-0.0851, -0.0394, -0.1714, -0.0799],
         [-0.0783,  0.0051,  0.0722, -0.0421],
         [ 0.1189,  0.1314,  0.0353,  0.0170],
         ...,
         [-0.0257,  0.0235,  0.1231,  0.0237],
         [-0.1434, -0.1931,  0.0226,  0.0802],
         [-0.0290, -0.0881, -0.0312, -0.0371]],

        [[ 0.1397,  0.0442,  0.0512,  0.0759],
         [ 0.0160, -0.0404,  0.0724, -0.0143],
         [-0.0313,  0.0492, -0.0448, -0.0947],
         ...,
         [-0.1008, -0.1132, -0.0222, -0.0444],
         [-0.1045, -0.1071, -0.1400, -0.1054],
         [ 0.0179,  0.0530,  0.0161, -0.0189]],

        [[ 0.0253,  0.1141,  0.1450,  0.0617],
         [-0.0418, -0.0299,  0.0451,  0.0960],
         [-0.0335, -0.0937, -0.1546, -0.1994],
         ...,
         [-0.1867, -0.0829, -0.1102, -0.1068],
         [ 0.0119,  0.0529,  0.0923,  0.1100],
         [ 0.0211, -0.0375, -0.0099,  0.0299]]], device='cuda:0')

Layer: history_encoder.conv_layers.0.bias 
Shape: torch.Size([20]) 
Values: tensor([-0.1080,  0.0808, -0.4165,  0.1497, -0.0230, -0.0700,  0.0648, -0.1734,
        -0.1490, -0.0751,  0.0501,  0.0455, -0.2295, -0.0923, -0.0094, -0.0420,
        -0.0860, -0.0039, -0.2475, -0.0105], device='cuda:0')

Layer: history_encoder.conv_layers.2.weight 
Shape: torch.Size([10, 20, 2]) 
Values: tensor([[[-6.1907e-02, -6.4281e-02],
         [-3.4692e-02, -3.1258e-02],
         [ 9.9476e-03, -2.8299e-02],
         [ 9.8229e-02,  5.2732e-02],
         [ 9.7487e-02,  7.9770e-03],
         [-4.3907e-02, -5.2286e-02],
         [-5.2560e-02, -3.2417e-02],
         [-6.4920e-02,  8.4918e-02],
         [ 8.3618e-02, -1.4624e-02],
         [-1.0226e-02, -4.2497e-03],
         [ 8.2465e-03,  1.0510e-04],
         [ 6.1969e-04,  7.7346e-02],
         [-1.2598e-01, -1.3102e-01],
         [ 1.1672e-01, -9.0828e-02],
         [ 4.7819e-02, -1.0215e-02],
         [ 2.0101e-02,  7.2985e-04],
         [ 6.2592e-02, -2.8067e-02],
         [-7.2320e-02,  1.7222e-03],
         [-1.0734e-01, -1.5351e-02],
         [ 8.9712e-02,  8.5014e-02]],

        [[ 1.5336e-02, -1.2574e-03],
         [-1.3176e-02, -4.6903e-02],
         [-3.4182e-02, -1.5239e-01],
         [ 2.7027e-02, -2.8676e-02],
         [ 2.6231e-02, -1.7925e-02],
         [ 4.1612e-02, -2.5454e-02],
         [-1.1411e-01, -5.2649e-02],
         [ 4.2105e-02,  1.2070e-01],
         [-1.1874e-01, -4.8968e-02],
         [ 5.8017e-02,  3.9699e-02],
         [-9.0715e-02, -1.1465e-01],
         [-1.0354e-02, -5.2348e-02],
         [-4.4639e-02, -1.4969e-01],
         [ 1.6377e-01,  4.2740e-02],
         [ 1.0339e-02, -3.9986e-02],
         [ 1.0489e-01,  1.0376e-02],
         [ 1.8492e-02, -5.2447e-03],
         [ 2.0989e-02,  3.3833e-02],
         [ 5.9102e-02,  8.6654e-02],
         [ 3.8817e-02,  1.5799e-01]],

        [[-1.0469e-01,  9.1125e-03],
         [ 3.1642e-02,  8.9521e-02],
         [-3.0588e-02,  9.4370e-02],
         [ 6.8954e-02,  4.2688e-02],
         [-8.1244e-02, -3.2555e-02],
         [-8.8256e-02, -7.0631e-02],
         [ 5.9652e-02, -4.0322e-02],
         [-1.3921e-01, -5.5827e-02],
         [ 1.3051e-01, -9.5281e-02],
         [ 6.0275e-02,  8.3658e-02],
         [-2.1174e-02, -4.2259e-02],
         [-1.0823e-03, -6.7590e-02],
         [-5.1697e-02,  1.8944e-02],
         [-6.6152e-02, -6.0644e-02],
         [-8.1380e-03, -1.4693e-01],
         [ 3.5194e-02,  3.7906e-02],
         [ 2.0549e-02, -7.4096e-02],
         [ 8.9949e-03,  1.7057e-03],
         [-1.1520e-01,  2.0494e-03],
         [ 1.5579e-02, -1.5725e-02]],

        [[ 1.9664e-02, -7.3638e-03],
         [-1.7420e-02,  7.7269e-02],
         [ 6.4857e-02,  8.5230e-03],
         [-3.2233e-03, -5.7954e-02],
         [ 6.9086e-02, -2.1308e-01],
         [-1.8935e-02, -6.6569e-02],
         [-6.4486e-02,  6.3219e-02],
         [ 9.5721e-02,  4.9422e-02],
         [-3.9347e-02,  1.1541e-01],
         [-1.6179e-02,  1.1384e-02],
         [-7.3814e-02,  1.1289e-01],
         [ 2.5499e-02,  4.1601e-02],
         [-2.9973e-02, -8.2119e-02],
         [-3.2524e-02,  4.5015e-02],
         [-5.3086e-02, -9.4912e-02],
         [-6.3374e-02, -1.2630e-01],
         [ 1.7517e-02,  1.1134e-01],
         [-9.3387e-02, -8.2993e-03],
         [ 4.2197e-02, -1.6762e-01],
         [ 3.9941e-02,  7.6542e-02]],

        [[ 3.0828e-02, -5.1231e-02],
         [-1.3879e-01, -4.8946e-02],
         [ 2.7501e-01,  2.8930e-01],
         [-1.7482e-02, -2.0863e-02],
         [-4.8629e-02, -6.2436e-02],
         [ 1.3514e-02, -2.8567e-02],
         [-7.0709e-02, -5.1309e-02],
         [-3.7489e-02,  1.4824e-01],
         [-2.0763e-02, -6.9081e-02],
         [-1.1371e-02,  2.4239e-03],
         [-1.1554e-01, -1.9527e-02],
         [-6.1969e-02, -1.7531e-01],
         [ 2.5007e-01,  1.7526e-01],
         [ 3.2227e-03, -7.0300e-02],
         [ 4.9332e-02, -2.6624e-02],
         [ 4.1692e-02, -4.5511e-02],
         [-8.8118e-02, -2.9534e-02],
         [ 1.5832e-02,  1.6828e-02],
         [ 7.4044e-02,  9.7669e-02],
         [-7.3019e-02, -1.0887e-02]],

        [[ 2.0477e-02,  7.9733e-03],
         [-8.1911e-02, -4.6348e-02],
         [-1.1818e-01, -8.7343e-03],
         [ 3.3843e-02,  2.0093e-02],
         [ 9.5169e-03,  6.3331e-02],
         [ 1.0225e-03, -1.7992e-02],
         [-1.6361e-01, -1.2501e-01],
         [-4.8107e-02,  5.4739e-02],
         [ 7.1604e-02, -1.5923e-02],
         [ 1.7773e-02,  6.8180e-02],
         [ 8.2908e-02, -3.1956e-02],
         [-2.2816e-02, -3.0363e-03],
         [-1.7154e-02, -8.1418e-02],
         [ 1.0215e-01, -1.0666e-01],
         [ 7.3091e-02,  1.3175e-03],
         [ 6.3683e-02, -3.7997e-02],
         [-8.4217e-04, -4.4912e-06],
         [-1.8575e-04,  1.7383e-02],
         [ 1.3341e-01,  1.0926e-01],
         [ 1.3478e-01,  7.5096e-02]],

        [[-8.2109e-02, -4.0644e-02],
         [-4.9810e-02,  4.5752e-02],
         [-5.6358e-02, -1.0650e-01],
         [-2.8638e-02, -6.4716e-02],
         [ 1.3609e-01, -8.1363e-02],
         [-4.0746e-02, -3.0462e-02],
         [ 2.3886e-02,  3.1863e-02],
         [-5.9437e-02,  1.4327e-01],
         [ 9.5741e-02, -8.5845e-02],
         [ 8.4157e-02,  1.0848e-01],
         [-5.3175e-02, -6.5239e-02],
         [-9.6578e-02, -6.3915e-02],
         [ 1.1843e-02,  1.1935e-02],
         [-6.6232e-02,  2.1144e-02],
         [ 6.1463e-02, -1.7337e-01],
         [-6.4750e-03, -9.7138e-02],
         [ 8.8278e-02,  2.3223e-02],
         [ 2.3099e-02,  1.3142e-01],
         [-8.3046e-02,  8.8100e-03],
         [-5.1617e-02, -2.4047e-02]],

        [[-8.2208e-02,  6.1953e-03],
         [-8.1198e-02, -1.5319e-01],
         [ 2.0764e-01,  2.3064e-01],
         [-9.9770e-02, -6.0071e-02],
         [-1.6059e-01,  7.8311e-02],
         [ 2.2377e-03, -2.5351e-03],
         [ 9.2169e-02, -2.1926e-02],
         [ 9.6622e-02,  8.3538e-02],
         [-5.1718e-02, -1.1922e-01],
         [ 3.1216e-02,  1.0006e-01],
         [-3.9244e-02, -5.6594e-02],
         [-7.6085e-02, -1.5809e-01],
         [ 9.6151e-02, -2.6622e-03],
         [ 6.6900e-02,  1.9873e-02],
         [ 1.3395e-01,  8.2170e-02],
         [ 7.0466e-03, -4.5150e-02],
         [ 5.5047e-02,  1.1365e-02],
         [ 1.5568e-01,  1.0139e-01],
         [ 8.6672e-02,  5.5436e-02],
         [-1.5868e-02,  4.9181e-02]],

        [[-3.5944e-02, -5.2865e-03],
         [ 4.0894e-02,  5.9785e-02],
         [-3.9674e-02,  1.5981e-01],
         [ 2.1679e-02, -4.6987e-02],
         [ 5.5343e-02,  3.6802e-02],
         [-1.8169e-02, -1.1681e-02],
         [ 2.7142e-02, -1.0552e-01],
         [-1.3896e-02,  1.1837e-02],
         [ 6.4933e-02, -3.0829e-03],
         [-6.3085e-02,  1.2804e-02],
         [-2.5380e-02,  3.7881e-02],
         [-2.4411e-02, -1.2991e-01],
         [ 1.0360e-01,  1.4213e-01],
         [-1.1958e-01, -8.8076e-03],
         [-2.1947e-02, -1.1774e-01],
         [ 4.2961e-02, -8.2064e-02],
         [-2.6786e-02,  3.7432e-02],
         [-2.5295e-02,  6.7652e-02],
         [ 6.4321e-03,  7.1967e-02],
         [-3.7187e-02, -9.0652e-02]],

        [[-3.8114e-03,  2.6668e-02],
         [ 3.2751e-03,  1.2339e-02],
         [ 2.5748e-01,  2.2751e-01],
         [-6.5430e-02, -9.2991e-02],
         [ 9.0857e-02,  1.5674e-01],
         [ 4.0647e-02,  6.5550e-02],
         [ 5.9989e-02, -2.1092e-01],
         [ 1.1042e-01,  1.3931e-01],
         [-4.8049e-02, -1.2576e-01],
         [ 1.0390e-01,  1.0609e-01],
         [-1.7067e-01, -6.7358e-02],
         [-7.5760e-02, -1.1676e-01],
         [ 1.4521e-01,  7.0754e-02],
         [ 1.0081e-01,  1.0469e-01],
         [ 1.7953e-02,  1.8212e-02],
         [ 2.5250e-02, -5.7507e-02],
         [ 7.7413e-02, -2.8009e-02],
         [ 4.3759e-02,  7.0077e-02],
         [ 1.2275e-01,  1.2835e-01],
         [ 1.9135e-02, -1.6706e-02]]], device='cuda:0')

Layer: history_encoder.conv_layers.2.bias 
Shape: torch.Size([10]) 
Values: tensor([-0.1332,  0.2377,  0.0053, -0.1966, -0.0654,  0.0153,  0.0064, -0.3390,
        -0.1025, -0.4137], device='cuda:0')

Layer: history_encoder.linear_output.0.weight 
Shape: torch.Size([20, 30]) 
Values: tensor([[ 7.5861e-02,  2.5934e-02, -1.4246e-01,  3.0948e-02, -7.2699e-03,
         -1.2613e-01,  8.7033e-02,  1.0478e-01,  6.2474e-02, -2.1604e-02,
         -2.2266e-02, -1.2505e-01, -8.7416e-03,  1.6235e-01, -4.2391e-02,
         -1.0555e-01, -3.5916e-02, -1.2936e-02, -5.6366e-02, -1.5232e-02,
          5.3087e-02,  3.5481e-02,  1.3015e-01,  5.9550e-02,  3.8583e-02,
          1.6159e-02,  6.1000e-02,  1.0663e-01, -3.2696e-02,  1.5970e-04],
        [ 7.2155e-02,  3.9561e-02,  1.0471e-01, -1.8749e-02, -4.1888e-02,
         -2.3633e-02, -5.9277e-02, -7.8008e-02, -6.5268e-02,  5.3357e-02,
          1.9037e-02,  2.2515e-01,  9.6483e-02,  1.4511e-01,  4.7350e-02,
          1.2577e-01,  1.0482e-03,  7.3493e-02, -3.0360e-02,  3.7056e-02,
          6.6390e-02,  1.0388e-01, -8.9187e-02,  2.0238e-01,  3.6896e-02,
         -1.7431e-02,  1.1246e-03, -9.4087e-02, -1.3616e-02, -1.2267e-01],
        [ 1.4006e-01, -4.7193e-02, -1.3585e-01,  5.3096e-02,  1.0596e-01,
          2.1229e-01,  2.6703e-02,  2.5754e-02,  1.0191e-01,  4.4320e-02,
          7.4288e-02, -1.5444e-02,  1.1852e-01,  2.0394e-02,  7.0007e-02,
         -1.2056e-01,  2.8513e-02,  9.2217e-03, -3.1405e-02, -1.9654e-02,
         -8.2603e-02,  1.9663e-01, -7.0143e-02,  3.3813e-02,  1.3113e-02,
          8.5828e-02,  1.7340e-01,  1.7887e-01,  5.4147e-02, -8.3169e-03],
        [ 1.9401e-02, -8.6115e-02,  2.3388e-02,  3.2368e-02, -2.0637e-02,
         -7.3264e-03, -3.0109e-02,  2.7719e-02, -7.1897e-02,  5.1635e-02,
          9.2928e-02,  4.9832e-02, -9.3198e-02, -1.9930e-02,  8.3555e-02,
         -1.1996e-01,  6.9444e-02,  7.8912e-03, -5.4337e-02, -1.6933e-02,
         -1.2391e-02,  9.5180e-02,  2.0275e-01, -1.0480e-02,  8.8005e-03,
         -7.8909e-02,  1.7647e-01,  4.1220e-02,  1.7731e-01,  5.2758e-02],
        [-5.7378e-02, -7.3037e-02, -8.9123e-02, -1.8313e-01,  2.3931e-02,
          1.5005e-03, -1.1911e-01, -5.5621e-03,  4.2798e-03, -4.5404e-02,
         -1.3976e-01, -2.8567e-01,  4.0371e-02, -5.1023e-02,  5.3433e-02,
         -1.4268e-02, -3.8154e-02,  1.1944e-02,  2.5051e-02, -9.8615e-03,
          5.8134e-02,  1.0615e-01,  6.3053e-02,  1.8012e-02,  4.5291e-02,
         -8.5289e-03,  4.8255e-02,  9.8697e-02,  2.1482e-01,  1.0585e-02],
        [ 6.4461e-02,  7.1870e-02,  6.3390e-02, -4.1458e-02, -1.6343e-01,
         -1.2712e-01, -1.7252e-02, -1.3291e-01, -8.9134e-02, -4.6729e-03,
          1.1956e-01,  2.9338e-01,  1.1767e-01,  1.3257e-01,  1.7921e-01,
         -2.1676e-02,  5.1647e-02,  1.2398e-01, -8.6573e-02,  2.1252e-02,
         -2.0622e-02,  5.2479e-02,  1.5030e-01,  9.1323e-02,  7.6714e-02,
          2.2834e-02,  3.2746e-02,  1.4311e-01, -1.7611e-02, -1.2540e-01],
        [ 4.6108e-02,  5.7328e-03,  3.1996e-02, -6.5031e-02,  3.3796e-02,
          1.1717e-01, -1.2849e-01, -6.7815e-02,  2.2908e-02,  1.2312e-02,
         -1.6934e-02,  1.7159e-01,  1.5646e-01,  6.6226e-02,  1.6047e-01,
          1.8710e-01,  3.6520e-02, -7.2236e-02,  5.5609e-03, -8.1517e-02,
         -2.9393e-02,  6.3584e-02, -4.1029e-02,  4.3490e-02,  8.9461e-02,
          2.7879e-02, -4.0794e-02, -4.6067e-02, -7.9626e-02,  2.0685e-01],
        [-8.9325e-02,  2.7999e-02, -4.0267e-02,  1.4950e-02,  4.9927e-02,
          1.8014e-01, -1.5084e-02, -5.3076e-02,  1.0622e-01, -5.4913e-02,
         -9.8699e-02,  4.2280e-02, -5.6737e-02, -7.6821e-02, -7.3557e-02,
          6.5808e-02, -7.1901e-02, -3.8251e-02,  5.0286e-02,  2.0264e-02,
          2.9731e-02, -2.1381e-01, -4.9819e-02, -2.0278e-01, -5.5813e-02,
          8.6900e-04,  1.3778e-02, -9.1981e-03, -1.4884e-01, -2.5240e-01],
        [-7.2723e-02,  6.5706e-02,  8.8049e-02, -4.5016e-03,  2.9731e-02,
         -1.1724e-01, -1.0558e-01, -7.4555e-02, -1.1540e-01,  6.9020e-02,
          7.5953e-02,  1.0404e-01,  1.7717e-01,  4.7627e-02,  6.9634e-02,
          1.0576e-01, -6.8201e-02,  4.6813e-02, -1.3555e-01, -1.0560e-01,
         -6.5669e-02, -1.0628e-02,  2.1317e-01, -5.9317e-02, -5.3514e-02,
          2.7797e-02, -8.2061e-03,  8.9105e-02, -4.1284e-02,  4.8178e-02],
        [ 3.8869e-02, -7.0778e-02,  1.6386e-01, -1.7320e-01, -1.7341e-01,
         -5.2797e-02,  6.8939e-02,  1.0020e-01,  5.0629e-02,  1.5774e-02,
          1.9612e-03, -4.0349e-02,  1.0960e-01, -5.8134e-02,  1.7155e-01,
          1.0030e-02, -6.5722e-02,  4.9347e-02, -6.1726e-02, -3.2898e-02,
         -5.8937e-02,  1.6771e-01,  1.9621e-01,  6.5586e-02, -1.8476e-02,
         -5.2605e-02,  8.0918e-03,  7.5764e-02,  1.3771e-01,  1.3079e-01],
        [-5.8714e-03, -6.2568e-02, -7.6988e-03,  9.1159e-02,  8.7665e-02,
          1.3649e-01, -2.8114e-02,  2.4363e-02,  3.5486e-02, -2.2979e-02,
         -9.6917e-02, -3.9272e-02,  3.7925e-03,  8.4712e-02, -2.5793e-02,
         -6.0355e-02, -9.3665e-02, -1.1728e-01, -1.4021e-01, -7.7861e-02,
         -8.2041e-02,  1.4426e-01, -1.0689e-01,  2.3468e-02,  4.9346e-02,
         -1.0176e-01, -8.8333e-02,  1.3673e-01, -2.9610e-02, -8.8651e-02],
        [ 2.0607e-01,  1.9038e-01,  1.2296e-01,  3.7916e-02, -2.0661e-01,
          3.1077e-02,  1.1390e-01, -7.8958e-02,  1.9378e-01,  5.3610e-02,
         -9.3512e-03,  3.3059e-01,  5.7290e-02,  9.4684e-02,  3.2265e-02,
          2.1464e-01,  4.5890e-02, -6.7785e-02,  4.1040e-02,  1.5250e-01,
          6.0595e-02,  9.7108e-04,  9.7635e-02,  3.0361e-02,  5.0793e-02,
         -1.0742e-02, -2.8773e-02, -2.9668e-02, -1.5694e-02,  8.6855e-02],
        [-4.5662e-02,  6.0028e-02, -6.6099e-03, -1.4010e-01, -9.4391e-02,
         -2.6639e-01, -5.6956e-02,  1.7967e-02, -1.3651e-01,  5.0375e-02,
          1.3449e-01,  1.6106e-01, -2.3111e-04, -1.1312e-02,  1.6876e-01,
          1.3423e-01,  2.8888e-02,  1.0136e-01, -2.8962e-02, -4.8598e-02,
          7.2306e-02,  2.3933e-01,  2.3120e-01, -7.4473e-02,  6.4410e-02,
          8.5223e-02, -4.9013e-02,  5.4998e-02,  1.1741e-01,  2.1292e-01],
        [-1.8389e-01, -6.9118e-02,  4.8765e-02,  1.1040e-01, -5.7424e-02,
         -1.2051e-01, -6.0189e-02, -2.3121e-02, -1.3310e-01, -3.9896e-02,
          4.5014e-02,  5.3897e-02, -2.5954e-02, -8.8343e-03,  1.4517e-01,
         -1.0177e-01,  3.9585e-02,  6.7452e-03, -3.3063e-02, -5.8682e-02,
         -3.7517e-02, -7.8530e-02, -1.1476e-01, -3.5817e-02,  2.8113e-02,
         -3.9742e-02,  1.1903e-01, -1.3879e-01,  2.2668e-01,  1.8846e-01],
        [-1.8771e-02,  4.6376e-02, -6.7987e-02,  2.8013e-02, -6.9747e-02,
         -1.7264e-01,  2.6011e-02, -4.7057e-02, -2.0646e-02, -1.2948e-01,
         -4.1445e-02,  3.2487e-01, -7.3250e-02,  2.6700e-02, -2.3914e-02,
         -1.1845e-01, -8.6419e-02, -3.6524e-02,  7.4465e-02,  4.6979e-02,
          1.0621e-01, -1.1014e-01, -6.7544e-02,  5.4073e-02,  1.1521e-01,
          1.4574e-02, -1.5723e-02, -1.2260e-02, -7.3515e-02,  2.5259e-02],
        [ 1.0164e-01,  4.5292e-02, -4.5655e-02, -1.0192e-01,  1.4622e-02,
         -1.1885e-01, -9.4546e-02,  6.1179e-02,  3.1597e-02, -1.6401e-02,
          6.4627e-02,  1.3720e-02,  6.9673e-02, -4.8026e-02, -9.8856e-02,
          1.1646e-02, -7.4917e-02, -1.3061e-01, -1.5209e-02, -1.1965e-01,
         -3.9722e-02,  1.5903e-01, -6.0960e-02,  1.5258e-02,  7.9331e-02,
         -2.1445e-04, -1.3484e-01,  8.0391e-02,  1.2764e-01,  2.0392e-01],
        [-1.3965e-02, -8.4895e-03,  1.7838e-01, -1.2945e-02,  6.3802e-02,
          1.6446e-01,  6.1278e-02,  8.7022e-02, -1.3178e-02,  5.7113e-02,
          6.7338e-02,  3.6841e-02,  5.2426e-02,  9.4882e-02,  1.5062e-01,
          8.2783e-03, -2.0670e-02, -3.6931e-02, -2.1255e-02, -2.1846e-02,
         -4.8974e-02, -3.0945e-02, -1.7995e-02,  1.1800e-01, -7.3244e-02,
          3.7583e-02, -7.4855e-03,  6.8907e-02,  2.2861e-02,  4.6349e-02],
        [-9.8702e-02, -8.6848e-03,  2.9467e-02, -1.0783e-01,  6.5451e-02,
          1.3783e-01,  3.1947e-02,  1.2542e-01, -2.2663e-03,  2.1782e-02,
          4.1321e-02, -1.1389e-01,  2.5609e-02, -2.2072e-02,  4.6666e-02,
         -1.2103e-01, -6.1601e-02,  3.4840e-02,  6.6816e-02, -4.4844e-02,
          5.2763e-03,  5.5508e-02,  2.6087e-03,  1.2975e-01, -4.9099e-03,
          1.2103e-02,  6.0545e-02, -1.1636e-01,  7.9319e-02, -6.2754e-02],
        [-3.0909e-02,  9.5198e-02, -3.1444e-02, -8.0068e-02, -9.1497e-02,
         -8.2374e-02,  5.8019e-02,  1.3730e-02,  8.3084e-02,  5.4931e-02,
          5.8901e-02, -1.0842e-01, -7.2888e-02,  1.9995e-01, -8.8066e-02,
         -1.5411e-01, -1.3360e-01,  8.2640e-02,  6.0252e-02, -4.5425e-02,
         -4.5754e-02,  2.1910e-01, -6.1965e-03,  1.9884e-01, -6.9561e-02,
          2.4596e-02, -3.5365e-02,  3.3886e-02,  2.0584e-01,  2.7994e-01],
        [ 2.2929e-01,  1.4219e-01,  1.5283e-01, -2.0209e-01, -9.2198e-02,
          5.2844e-02,  3.2778e-02,  2.0429e-01,  2.0472e-02, -1.6780e-03,
          8.3441e-02, -3.0431e-01,  1.4504e-01, -9.9028e-02, -2.3456e-02,
         -6.9147e-02, -1.5862e-02,  6.4634e-02, -6.6492e-03, -7.1211e-02,
         -4.5950e-02,  2.5217e-02,  1.4969e-01,  1.1825e-02, -2.9373e-02,
         -6.6055e-03, -8.7280e-02,  1.2982e-01,  2.2135e-01,  1.5118e-01]],
       device='cuda:0')

Layer: history_encoder.linear_output.0.bias 
Shape: torch.Size([20]) 
Values: tensor([-0.0998,  0.1421, -0.2682, -0.2248, -0.0443,  0.0481, -0.1593,  0.0992,
         0.0051,  0.0864, -0.1364, -0.0287, -0.1043, -0.2269, -0.1197, -0.0313,
        -0.1428, -0.1881,  0.0874,  0.0255], device='cuda:0')

Layer: scan_encoder.0.weight 
Shape: torch.Size([128, 132]) 
Values: tensor([[ 1.6618e-02, -1.0801e-01, -2.0447e-01,  ..., -2.3102e-03,
          1.7307e-01,  1.4422e-01],
        [-8.8885e-02, -2.8413e-02,  4.0746e-02,  ..., -2.2531e-02,
         -2.2307e-03,  2.7498e-02],
        [ 5.8248e-02,  3.1576e-02,  3.0149e-02,  ..., -2.0867e-01,
          2.2844e-03,  2.3759e-01],
        ...,
        [ 5.8089e-02, -2.6858e-03,  1.0310e-01,  ...,  1.2768e-01,
         -1.6867e-01,  6.6219e-03],
        [ 4.6702e-02,  5.3298e-03,  1.1113e-01,  ...,  3.6092e-02,
          1.5726e-01,  2.3931e-01],
        [-7.0552e-02, -2.7628e-02, -5.4869e-02,  ..., -1.4307e-04,
         -1.4923e-01, -1.6960e-01]], device='cuda:0')

Layer: scan_encoder.0.bias 
Shape: torch.Size([128]) 
Values: tensor([-0.2112, -0.1183,  0.0052, -0.1006, -0.0010, -0.0722,  0.2178,  0.1577,
        -0.0208, -0.0519, -0.0298, -0.0378,  0.0184,  0.0344,  0.1469,  0.0562,
         0.0108, -0.0098, -0.0338,  0.0131,  0.0581,  0.0018, -0.1887,  0.0760,
        -0.0763,  0.0339, -0.0140, -0.0512, -0.1320, -0.0517, -0.0672, -0.0983,
        -0.2003,  0.0422, -0.0450, -0.0881, -0.0915,  0.0694,  0.0145,  0.0110,
        -0.0812, -0.0681,  0.1524, -0.0340,  0.1046, -0.0569, -0.0119,  0.1562,
        -0.1104, -0.1705,  0.0530,  0.0630,  0.0909,  0.0816, -0.1377, -0.0800,
        -0.0068, -0.0184, -0.0917, -0.0335,  0.0061, -0.0059,  0.1350, -0.0457,
         0.1155,  0.0940, -0.1263, -0.0974, -0.0387, -0.1306,  0.0800,  0.0617,
        -0.0649,  0.0205, -0.0430, -0.1161, -0.1553, -0.0078, -0.0496,  0.0633,
        -0.0438,  0.2274, -0.0703, -0.0200,  0.1011,  0.0439,  0.0462,  0.0361,
         0.0978, -0.1066,  0.0253, -0.0307,  0.0454, -0.0106,  0.0894,  0.0397,
        -0.1471,  0.0345, -0.0802,  0.2325, -0.0447, -0.0262, -0.1511, -0.1288,
        -0.1508, -0.0750, -0.1884,  0.0596, -0.1063,  0.0813, -0.1777,  0.0719,
        -0.0760, -0.0121, -0.0044,  0.0448,  0.1773,  0.0616, -0.1022,  0.0329,
        -0.0951, -0.0950,  0.0566, -0.0214,  0.0316,  0.0439, -0.1156,  0.0252],
       device='cuda:0')

Layer: scan_encoder.2.weight 
Shape: torch.Size([64, 128]) 
Values: tensor([[-0.0316, -0.1270,  0.0009,  ...,  0.0381,  0.0216,  0.0748],
        [ 0.0893, -0.1389,  0.0856,  ..., -0.0640,  0.1618, -0.0135],
        [-0.0398,  0.0910,  0.0417,  ...,  0.0348, -0.0693,  0.0861],
        ...,
        [-0.0791, -0.0635,  0.1387,  ...,  0.0330, -0.1009, -0.1204],
        [-0.0439,  0.1153, -0.0489,  ...,  0.0533, -0.1033,  0.0303],
        [ 0.0586, -0.0317, -0.0413,  ..., -0.0161,  0.0707,  0.0061]],
       device='cuda:0')

Layer: scan_encoder.2.bias 
Shape: torch.Size([64]) 
Values: tensor([ 5.0452e-03, -1.2067e-01,  2.7081e-02,  2.1926e-04,  2.6990e-03,
        -3.9028e-02, -8.6551e-02, -5.9418e-02,  5.6598e-02, -8.5177e-02,
        -8.2242e-02,  5.8017e-02, -1.1944e-01, -1.2531e-02,  2.5056e-02,
        -8.6343e-02, -1.5016e-01, -4.4691e-02,  6.3393e-03, -8.9955e-02,
        -1.1535e-01, -1.5046e-01, -4.6103e-02,  6.4567e-02, -4.8105e-02,
         2.4680e-02, -3.2795e-02, -9.4775e-02,  3.9708e-02, -2.5212e-01,
        -8.3183e-02,  7.1244e-02, -2.2040e-02,  3.1781e-04, -6.5212e-02,
        -7.0722e-02,  1.0978e-02, -1.0252e-01,  9.3356e-02,  6.5521e-02,
         9.7423e-02, -3.4716e-01,  9.2016e-02, -1.0171e-01, -1.1676e-01,
        -2.8295e-01, -1.2221e-01, -4.7159e-02, -1.9861e-01, -2.9964e-02,
         3.2664e-04,  4.6587e-02,  6.9593e-02,  1.5355e-02, -1.0209e-01,
        -1.3317e-02, -2.9388e-02, -9.6075e-02, -1.0101e-01,  1.0257e-02,
        -1.2098e-01,  6.6913e-03, -1.8781e-02, -2.6121e-02], device='cuda:0')

Layer: scan_encoder.4.weight 
Shape: torch.Size([32, 64]) 
Values: tensor([[ 0.1421,  0.0815, -0.0081,  ...,  0.0049,  0.1450, -0.0304],
        [-0.0632,  0.0900,  0.0229,  ..., -0.0608,  0.0305, -0.0467],
        [ 0.0331,  0.0613,  0.0121,  ..., -0.0052,  0.0164,  0.0225],
        ...,
        [-0.0155,  0.0096,  0.0726,  ...,  0.0556,  0.0386,  0.0365],
        [ 0.0271,  0.1133,  0.0006,  ..., -0.1200,  0.0413, -0.0610],
        [ 0.0180, -0.0003,  0.0495,  ..., -0.0142,  0.0130,  0.0285]],
       device='cuda:0')

Layer: scan_encoder.4.bias 
Shape: torch.Size([32]) 
Values: tensor([-0.0144, -0.1550, -0.1210,  0.0613,  0.0151,  0.0722, -0.0468,  0.0082,
        -0.0003, -0.0370, -0.0440,  0.0286,  0.0930,  0.0293,  0.0481,  0.0226,
         0.0076, -0.0357,  0.0173, -0.1606, -0.0987,  0.0850, -0.0271, -0.0881,
         0.0718,  0.0348,  0.0349,  0.0223, -0.0378, -0.0183, -0.0210, -0.0803],
       device='cuda:0')

Layer: actor_backbone0.0.weight 
Shape: torch.Size([512, 116]) 
Values: tensor([[ 0.0365,  0.0908,  0.3868,  ...,  0.0634,  0.0164, -0.1570],
        [-0.0463, -0.1384, -0.4443,  ..., -0.1126, -0.0809, -0.1175],
        [-0.0729,  0.1286, -0.2103,  ..., -0.1578, -0.0357,  0.0157],
        ...,
        [ 0.0205, -0.0961,  0.0126,  ..., -0.0826, -0.0194,  0.0195],
        [ 0.0659, -0.1331,  0.0026,  ...,  0.1445, -0.0098, -0.0184],
        [ 0.0070, -0.0429,  0.1400,  ...,  0.0398,  0.0756, -0.0681]],
       device='cuda:0')

Layer: actor_backbone0.0.bias 
Shape: torch.Size([512]) 
Values: tensor([-1.1339e-01, -4.8809e-02, -4.0431e-02, -4.2879e-02, -1.6929e-01,
         1.1283e-01, -4.1937e-02, -2.3223e-01, -6.7557e-02,  6.5116e-02,
        -1.5279e-01, -1.2726e-01, -2.9231e-02, -1.8772e-01, -1.4447e-01,
        -1.5385e-01,  2.1827e-02, -1.2752e-01, -5.9151e-02,  9.1746e-03,
        -4.7906e-02, -8.5514e-02,  6.2696e-02,  6.4726e-02, -4.2488e-02,
         8.3752e-02, -6.2482e-02,  1.0704e-01, -5.9640e-02, -8.0911e-02,
        -8.5396e-02, -1.3404e-01, -1.0076e-01,  2.6700e-02, -4.6685e-02,
         1.2798e-02,  5.6492e-02,  5.5752e-02,  1.4093e-01, -3.5904e-01,
        -1.4771e-01, -2.3006e-02, -3.2220e-02, -7.3193e-02, -9.6960e-02,
         3.3943e-02, -1.6533e-01, -1.0452e-02, -1.0144e-01,  1.4728e-02,
         5.1937e-02, -6.7882e-02, -1.5978e-01, -1.8923e-01, -2.4391e-02,
         3.8171e-02,  9.7989e-02,  8.9304e-02,  5.5480e-02,  3.6445e-02,
         7.9094e-02, -4.1727e-02, -1.2329e-02,  1.1317e-02, -3.9376e-02,
        -1.0030e-01, -9.1537e-02,  7.7494e-02,  3.8392e-02,  9.2914e-03,
         4.4787e-02, -3.7133e-02,  4.1054e-02, -1.7317e-01, -6.3596e-02,
        -7.8428e-02, -9.9089e-02,  2.3027e-02, -1.4330e-01, -1.3025e-01,
         6.5472e-02, -1.1235e-01, -3.3650e-03, -1.1422e-01, -1.1027e-01,
        -4.7753e-02,  6.9461e-02, -1.2152e-01,  8.4966e-02, -1.8357e-01,
         1.9172e-02,  2.1458e-01, -8.9077e-02, -7.0712e-02, -3.0298e-02,
        -1.1260e-01,  2.2401e-02, -3.0605e-03,  1.3642e-01, -4.9677e-02,
        -2.9244e-02, -8.8860e-02, -6.1978e-02, -1.5905e-01, -1.5672e-01,
         3.0930e-02, -1.4011e-01, -1.1814e-01, -1.5276e-01,  3.0129e-02,
        -4.0061e-02, -1.4843e-01, -1.2603e-01, -1.0466e-01,  4.2559e-02,
        -1.1020e-01, -8.3274e-02, -1.0124e-01,  7.3438e-02, -6.3226e-02,
        -1.1102e-01,  1.5925e-01,  7.5829e-02, -1.0814e-02, -1.5427e-01,
        -6.1319e-03,  2.1265e-02, -8.7405e-02,  2.4484e-03, -6.7010e-02,
        -1.4786e-01, -2.6562e-02, -2.0857e-01,  7.1468e-02,  1.2090e-01,
         5.5099e-03, -9.4378e-02,  7.9770e-02,  2.0884e-02,  3.1642e-02,
         8.2427e-02, -2.1735e-01,  7.6540e-02, -6.4845e-02, -8.3126e-02,
         5.4514e-02, -6.4537e-02,  1.1007e-01,  4.7515e-02,  4.9176e-02,
        -1.3299e-01, -5.3234e-02, -3.8691e-02,  5.7637e-04, -5.4030e-02,
        -1.1167e-01,  9.2518e-02, -1.2548e-02, -8.4980e-03,  7.1401e-02,
        -9.0689e-02, -9.2788e-02, -1.2203e-02, -6.6777e-02, -8.2201e-02,
        -1.6361e-01,  7.0094e-02,  1.2941e-02,  4.9280e-02, -5.3750e-02,
        -1.8170e-01,  5.7574e-03,  5.5547e-02, -1.4704e-01, -1.5384e-01,
         4.8507e-02, -8.5929e-02,  2.7395e-02,  1.1318e-01,  2.8378e-02,
        -1.0960e-02, -9.5858e-02, -8.6665e-02, -5.5399e-02,  1.0069e-02,
        -6.8357e-02, -7.1210e-02,  4.6654e-02,  3.6454e-02, -8.6726e-02,
         3.1230e-03, -2.0717e-01, -2.7579e-01,  5.0573e-02, -1.0653e-01,
         2.9009e-03, -4.0714e-02, -1.0221e-01, -1.5127e-01,  9.5147e-03,
        -1.7134e-02, -7.3430e-02, -9.9978e-02, -9.8919e-02,  8.4815e-03,
        -8.2592e-02, -6.7266e-02, -9.6826e-03, -8.7242e-02, -8.3305e-02,
        -1.6114e-02, -1.8536e-01, -1.1276e-01, -4.7959e-02, -5.4296e-04,
        -1.6582e-01, -4.6188e-02, -2.3150e-02,  3.2718e-02,  1.2943e-01,
         1.6901e-02, -1.5394e-01,  5.7830e-02, -2.2042e-02,  6.9309e-03,
        -1.2623e-01,  3.4445e-02, -9.9424e-02, -1.3848e-01, -2.8251e-02,
         4.9223e-02, -1.4428e-01, -6.1095e-02, -2.3476e-02,  2.0691e-02,
         1.0261e-01, -7.4741e-02, -1.7909e-01,  1.0651e-01, -8.6426e-04,
        -4.3318e-03, -7.2466e-03, -3.5919e-02,  3.0466e-02, -1.0341e-01,
         5.7630e-03, -8.5474e-02, -1.4434e-01, -1.5480e-01, -2.5053e-02,
        -4.4236e-02,  5.3635e-02, -7.0366e-02, -1.3719e-01, -1.6191e-02,
        -7.2562e-02,  3.9982e-02, -1.6733e-01, -7.6896e-02,  5.0744e-02,
        -5.5588e-02,  1.2659e-02, -6.0909e-02,  1.3639e-02, -7.7194e-02,
        -2.2235e-02,  1.1953e-01, -7.7530e-02,  1.5922e-02,  6.5172e-02,
        -6.6715e-02, -1.3185e-01, -3.6539e-02, -2.5342e-01, -2.0136e-01,
        -2.2127e-01, -1.7952e-01, -7.1856e-02,  5.4732e-03,  2.3942e-02,
        -2.6986e-02,  5.7653e-02, -6.8164e-02,  2.4354e-02, -8.8957e-04,
        -1.4475e-01, -2.9449e-02, -5.3220e-02,  5.6495e-03, -8.5985e-02,
         1.6326e-02,  1.4066e-01, -3.0314e-02, -8.4192e-02, -1.5325e-01,
        -4.9866e-02,  4.0560e-02, -8.7530e-02, -1.2475e-01, -5.5606e-02,
        -1.3442e-01,  1.0178e-01, -1.2142e-01,  1.0284e-01, -5.0753e-03,
        -1.0671e-01, -7.3634e-02, -2.6272e-01, -1.3593e-02, -3.2255e-02,
         2.3464e-02, -1.8638e-01, -3.7091e-02, -1.1481e-02, -1.1226e-01,
         1.6735e-01,  3.4454e-02, -5.3492e-02,  5.9072e-02,  7.3514e-02,
        -9.9571e-02, -1.7959e-01,  6.2259e-02, -2.0973e-01, -1.3202e-01,
        -1.7857e-01,  3.2049e-02, -1.4404e-01, -5.9454e-02, -6.9694e-02,
        -2.1148e-01, -4.1848e-02, -7.5747e-02,  7.4620e-02,  4.7644e-02,
         1.2480e-01, -2.8076e-01, -1.7734e-01,  8.4557e-03, -1.6963e-02,
        -2.5477e-01, -2.9382e-02,  1.6732e-02, -2.0453e-01,  3.3496e-02,
        -8.6999e-02,  1.7938e-02, -6.1865e-02,  7.7093e-02,  6.7149e-02,
         3.3642e-02,  7.3263e-02,  1.9159e-02, -2.0889e-02, -1.2473e-01,
        -1.9939e-01, -3.4297e-02, -1.7092e-01, -1.8052e-01, -1.5651e-02,
         2.3542e-02,  5.3105e-02, -7.3776e-03,  1.6412e-02, -6.8421e-02,
         2.4102e-02,  2.5768e-02, -4.5213e-03,  5.9364e-02,  2.6431e-02,
        -1.3157e-03, -2.3574e-01, -1.2448e-01, -2.5514e-02, -1.8820e-01,
         7.7862e-02,  1.0522e-03, -5.7071e-02,  4.5001e-02, -2.8509e-02,
        -1.8787e-01, -1.0536e-01, -1.0201e-01,  7.3460e-02,  2.2104e-02,
        -5.4738e-02, -2.5642e-01, -5.9034e-02, -1.6001e-01,  2.4507e-02,
         3.4905e-03,  1.8175e-02,  1.3099e-01, -1.9078e-01, -3.7584e-02,
        -2.0753e-01, -2.7570e-02, -1.9008e-01, -1.2843e-01,  3.7084e-03,
        -1.1053e-01, -3.7125e-02, -3.4098e-02, -4.1108e-02, -1.1626e-01,
         1.7245e-02, -1.1571e-01, -3.3355e-02,  1.4515e-02, -1.1570e-01,
         2.2410e-02,  2.5876e-04, -4.5014e-03, -6.2878e-02,  8.3519e-02,
         4.6964e-02, -1.8292e-03, -3.5436e-02, -4.1798e-02, -8.0134e-02,
        -8.1879e-02, -5.7795e-02, -7.7477e-02,  3.1858e-02,  8.0696e-02,
        -8.5767e-02, -2.6358e-01,  1.8676e-02, -5.1890e-02, -6.2867e-02,
        -7.1225e-02, -1.8783e-01, -2.3451e-03,  1.5959e-02,  3.1145e-02,
        -2.8402e-02,  1.8944e-02, -1.2830e-01,  7.5476e-02, -4.0249e-02,
        -1.4810e-01, -1.0844e-01, -1.4328e-01, -4.5261e-02,  8.8622e-03,
         1.2471e-01, -1.7001e-02,  5.4910e-02, -5.0880e-02, -2.4144e-01,
        -1.2770e-01, -1.5983e-01, -1.0139e-01, -1.4823e-01,  3.2447e-03,
        -9.5825e-02,  9.7231e-03,  7.9247e-02, -3.1227e-02, -1.2638e-01,
         4.7269e-02, -3.1556e-02, -1.2803e-01, -2.1353e-02,  1.0048e-01,
        -7.9859e-02, -4.3268e-02, -1.5627e-01, -3.7200e-02,  3.2421e-02,
         1.2025e-01,  4.0183e-02, -8.6529e-02,  1.1377e-01, -1.5642e-01,
         7.0950e-02,  1.1275e-01,  6.0967e-02, -1.7934e-01,  1.1339e-02,
        -1.8716e-02, -1.2442e-01,  2.9320e-03,  6.9206e-02, -1.1122e-01,
        -3.7828e-02,  5.5059e-03,  4.8204e-02, -1.8771e-01, -2.0366e-01,
        -8.5178e-03,  3.0816e-02,  5.8128e-02, -3.1947e-02, -2.8219e-02,
        -2.3827e-01, -1.4310e-01, -6.1207e-02, -5.8185e-03, -2.2429e-01,
         3.5474e-02, -4.6924e-02, -2.1809e-01, -4.7334e-02, -7.1302e-02,
        -6.3135e-02, -1.1473e-01,  1.2213e-01, -2.6971e-02,  1.9676e-03,
         1.8170e-02, -1.7702e-01], device='cuda:0')

Layer: actor_backbone0.2.weight 
Shape: torch.Size([256, 512]) 
Values: tensor([[ 0.0129,  0.0406,  0.0590,  ..., -0.0719, -0.0198, -0.0945],
        [-0.0409, -0.0537, -0.0903,  ...,  0.1487, -0.0140,  0.1348],
        [ 0.0213,  0.1224, -0.0542,  ..., -0.0063, -0.0499,  0.1004],
        ...,
        [ 0.0508,  0.0613,  0.0187,  ..., -0.1019,  0.1849,  0.3050],
        [-0.1203,  0.0125,  0.0252,  ...,  0.0105, -0.0813, -0.0476],
        [-0.1778,  0.0215, -0.0507,  ..., -0.0058, -0.2262,  0.0090]],
       device='cuda:0')

Layer: actor_backbone0.2.bias 
Shape: torch.Size([256]) 
Values: tensor([-0.0616, -0.0886, -0.0793, -0.1513, -0.1515, -0.0669, -0.1124, -0.1281,
        -0.1347, -0.0925, -0.0527, -0.1649, -0.0685, -0.0930, -0.1052, -0.0647,
         0.0574, -0.1017, -0.1489, -0.2140, -0.1990, -0.0940, -0.0416, -0.0977,
        -0.1421, -0.1117, -0.0874, -0.1026, -0.0986, -0.0649,  0.0006, -0.1945,
        -0.0467,  0.0070, -0.0542, -0.1672, -0.0113, -0.0647, -0.0342, -0.0299,
        -0.1581, -0.1541, -0.0682, -0.1645, -0.0994,  0.0073, -0.1195, -0.1207,
        -0.1067, -0.1188, -0.0631, -0.1116, -0.1753, -0.0878, -0.1211, -0.2955,
         0.0311, -0.0745, -0.0606, -0.0995, -0.0417, -0.1295, -0.1115, -0.2839,
        -0.1310, -0.0757, -0.0555, -0.0804, -0.0599, -0.0460, -0.0364, -0.0469,
        -0.0746, -0.1529, -0.0052, -0.0708, -0.0305,  0.0779, -0.1070,  0.0387,
        -0.0977, -0.1500, -0.0750, -0.1831, -0.0916, -0.1833, -0.1040,  0.0680,
        -0.1238, -0.1823, -0.1808, -0.1140,  0.0030, -0.0949, -0.0715, -0.1096,
        -0.1693, -0.1067, -0.0752, -0.0859, -0.1443, -0.1347, -0.1099, -0.1542,
        -0.1613, -0.1083, -0.0992, -0.1219, -0.0247, -0.0819, -0.1688, -0.0412,
        -0.0455, -0.1090, -0.0645, -0.1266, -0.1837, -0.0973, -0.1035, -0.1000,
        -0.0950, -0.0662,  0.0036, -0.0429, -0.0670, -0.0821, -0.1312, -0.1508,
        -0.0372, -0.0894, -0.0976, -0.0746, -0.0713, -0.1642, -0.0018, -0.1273,
        -0.1553, -0.0200, -0.1768, -0.0490, -0.1927, -0.0494, -0.0337, -0.1640,
        -0.0526, -0.0080, -0.0692, -0.1169, -0.0117, -0.0551, -0.1640, -0.0800,
        -0.1127, -0.1346, -0.1111, -0.0621, -0.0166, -0.1703, -0.0665, -0.2001,
        -0.1937, -0.0139, -0.2363, -0.1000, -0.0941, -0.0899, -0.2121, -0.1465,
        -0.0854, -0.1639, -0.1805,  0.0086, -0.1410, -0.1223,  0.0113, -0.1301,
        -0.1733, -0.0960, -0.0573, -0.0175, -0.0812, -0.0825, -0.1663, -0.1824,
        -0.1209, -0.1738, -0.1236, -0.0561, -0.1314, -0.1158, -0.1354, -0.3055,
        -0.0057, -0.0468, -0.0851, -0.2053,  0.0897,  0.0136, -0.0715, -0.1762,
        -0.1218, -0.1477, -0.1658, -0.0790, -0.0877, -0.1809, -0.0518, -0.0316,
        -0.1777, -0.2355, -0.1290, -0.0422, -0.1485, -0.1122, -0.1258, -0.0043,
        -0.2006, -0.0387, -0.0244, -0.1726, -0.0874, -0.1572, -0.0838, -0.1936,
        -0.0435, -0.0026, -0.0658, -0.0973, -0.0628, -0.0573, -0.0581, -0.1063,
        -0.0161, -0.0652, -0.1176, -0.0893, -0.0640, -0.2163, -0.0740, -0.0452,
        -0.0548, -0.1333, -0.1135, -0.0677, -0.0714, -0.0829, -0.1139, -0.0704,
        -0.0680, -0.0760,  0.0037, -0.0565,  0.0197, -0.1644, -0.1168, -0.1238],
       device='cuda:0')

Layer: actor_backbone0.4.weight 
Shape: torch.Size([128, 256]) 
Values: tensor([[-0.1595, -0.0381,  0.1702,  ...,  0.1348,  0.0603,  0.0474],
        [ 0.0612,  0.0951,  0.1215,  ...,  0.0416, -0.1692,  0.0408],
        [-0.1385,  0.1174,  0.0170,  ...,  0.0317,  0.0395,  0.1296],
        ...,
        [-0.1178,  0.0168, -0.0326,  ..., -0.0308,  0.1284, -0.0137],
        [ 0.0541,  0.0253,  0.0642,  ..., -0.0044,  0.0692,  0.1367],
        [ 0.0436,  0.0822,  0.0675,  ..., -0.0248,  0.1349, -0.1362]],
       device='cuda:0')

Layer: actor_backbone0.4.bias 
Shape: torch.Size([128]) 
Values: tensor([-0.0833, -0.1160, -0.1055, -0.0488, -0.0432,  0.1344, -0.1014, -0.0903,
         0.1034, -0.0889, -0.0177, -0.0761, -0.1062, -0.1202, -0.0209, -0.0791,
        -0.1765, -0.1145, -0.0381, -0.0489,  0.0326, -0.1527, -0.0953, -0.1154,
        -0.0836, -0.1057, -0.0202, -0.0511, -0.0734, -0.1203, -0.0728, -0.1019,
        -0.1191, -0.1378, -0.0804,  0.0576, -0.0192, -0.1335, -0.0664, -0.1211,
        -0.0287, -0.0131,  0.0160, -0.0608, -0.0985, -0.0582,  0.0201, -0.0868,
        -0.0973, -0.0435, -0.1120,  0.0076, -0.0948,  0.0246, -0.1156, -0.1014,
        -0.0541,  0.0314, -0.1326, -0.0060, -0.2258, -0.0918, -0.0734, -0.0465,
        -0.2300, -0.1263, -0.0212, -0.0510, -0.1256, -0.0764, -0.0149, -0.0903,
        -0.1485, -0.1543, -0.1280, -0.2139, -0.0756, -0.0922, -0.0866, -0.1334,
        -0.0895, -0.0910,  0.0586, -0.0092, -0.1040, -0.0473,  0.0830,  0.0254,
         0.0997, -0.0483, -0.0091, -0.0830,  0.0527,  0.0499, -0.2329, -0.1603,
        -0.0421, -0.0281, -0.1199, -0.0441, -0.0598, -0.0603, -0.0566,  0.0057,
        -0.1196, -0.0670, -0.0590, -0.0765, -0.1765,  0.0278, -0.0548, -0.0410,
        -0.0182,  0.1572, -0.0039,  0.0889,  0.0914, -0.0801, -0.0450, -0.0536,
        -0.0573, -0.0592, -0.1052,  0.0864, -0.0891, -0.1813,  0.0224, -0.0355],
       device='cuda:0')

Layer: actor_backbone0.6.weight 
Shape: torch.Size([13, 128]) 
Values: tensor([[ 0.0194, -0.0288, -0.1258,  ..., -0.0085, -0.0667, -0.0401],
        [-0.0059,  0.0629,  0.1298,  ..., -0.0662, -0.0387, -0.0683],
        [-0.0387, -0.1573,  0.1201,  ..., -0.2594,  0.0249,  0.0278],
        ...,
        [ 0.0281,  0.0507,  0.0301,  ..., -0.0400, -0.0416, -0.0208],
        [-0.6941, -0.0369, -0.2813,  ..., -0.1241,  0.2690,  0.1346],
        [ 0.0668, -0.1177, -0.0449,  ..., -0.0149,  0.2695,  0.2058]],
       device='cuda:0')

Layer: actor_backbone0.6.bias 
Shape: torch.Size([13]) 
Values: tensor([-0.0690,  0.0289,  0.0994,  0.1686,  0.0275,  0.1699, -0.0117,  0.0069,
         0.3826,  0.0402,  0.0524,  0.5039,  0.2020], device='cuda:0')

Layer: actor_backbone1.0.weight 
Shape: torch.Size([512, 116]) 
Values: tensor([[-0.1151, -0.1925,  0.3256,  ..., -0.0790,  0.2251, -0.0733],
        [ 0.0721,  0.7612, -0.5244,  ...,  0.1545,  0.2077,  0.0416],
        [ 0.1176,  0.2969,  0.3325,  ..., -0.1576, -0.0611, -0.0076],
        ...,
        [ 0.0322, -0.2025,  0.2131,  ..., -0.0132,  0.0133,  0.1116],
        [-0.1679,  0.1724,  0.0422,  ...,  0.0584,  0.2946, -0.0169],
        [ 0.0728,  0.1649, -0.1065,  ...,  0.0899,  0.0772, -0.0621]],
       device='cuda:0')

Layer: actor_backbone1.0.bias 
Shape: torch.Size([512]) 
Values: tensor([-0.0899, -0.0024,  0.0680,  0.1665, -0.0847,  0.0386, -0.1595, -0.0543,
        -0.0950, -0.0713, -0.0513,  0.0673,  0.0478, -0.2371, -0.1923, -0.1846,
        -0.2351, -0.1560, -0.2168,  0.1211,  0.0427,  0.0792, -0.1318,  0.0437,
         0.0602, -0.0393, -0.0369,  0.0471,  0.0610,  0.0209, -0.1211, -0.2006,
        -0.0252, -0.0632, -0.1022, -0.1194, -0.1131, -0.0359, -0.3098, -0.1437,
        -0.2525, -0.0836, -0.1959, -0.1871, -0.0540,  0.0608, -0.0693,  0.0116,
        -0.0438, -0.2612, -0.2044, -0.1277,  0.0502, -0.2301, -0.0818, -0.0668,
        -0.1181, -0.0617, -0.1872, -0.0267, -0.0007, -0.0967, -0.0550, -0.1328,
        -0.1115, -0.0214, -0.0599, -0.2568, -0.1154, -0.0180, -0.2280, -0.2032,
         0.0099, -0.0577,  0.1372, -0.2502, -0.0578,  0.0673,  0.0753, -0.1376,
        -0.1751,  0.0726,  0.0088, -0.1116,  0.0274, -0.0603, -0.0192,  0.0085,
        -0.0697, -0.1842,  0.0225,  0.0381, -0.0818,  0.0914, -0.0675, -0.2080,
        -0.0281, -0.0887,  0.0835, -0.0251,  0.1031, -0.0602,  0.1588,  0.0364,
        -0.0643, -0.0901, -0.0019, -0.0369, -0.1662, -0.1789, -0.1227, -0.2494,
         0.0582, -0.1042, -0.0807,  0.0460,  0.0050, -0.1378, -0.1467,  0.0348,
        -0.1118, -0.1821, -0.1722, -0.0973, -0.0759, -0.0533,  0.0404, -0.2504,
        -0.0014, -0.1613, -0.0516, -0.1752, -0.0463, -0.0509, -0.0660, -0.0709,
        -0.3583, -0.2164,  0.0153,  0.0109, -0.0685, -0.1481, -0.1975,  0.2544,
        -0.1813,  0.0249, -0.2029, -0.0690, -0.0867, -0.1076,  0.0208,  0.0334,
        -0.2538,  0.0487, -0.1756, -0.1276, -0.1333,  0.0170,  0.0596, -0.1492,
         0.0136, -0.1075, -0.0576, -0.1207, -0.1009, -0.0183, -0.0625, -0.2383,
         0.0038, -0.0338,  0.0874,  0.1125, -0.0928, -0.0843, -0.3777,  0.0021,
        -0.1911, -0.0326, -0.1044,  0.0142,  0.0522, -0.1590, -0.0346, -0.0459,
        -0.0638, -0.0119,  0.0046, -0.0412, -0.0400, -0.1190,  0.0176,  0.1569,
        -0.1960, -0.0413, -0.0422, -0.1116, -0.0906, -0.2230, -0.0813, -0.0098,
        -0.0635, -0.1848,  0.0239, -0.0720, -0.3387, -0.1239, -0.0943, -0.1004,
        -0.0578,  0.0201, -0.0044, -0.1416, -0.2480, -0.0841, -0.0865, -0.0404,
        -0.0238,  0.0064, -0.0643, -0.0148,  0.0689,  0.0316,  0.0706,  0.0341,
        -0.0736, -0.0782, -0.1007, -0.0031, -0.0759,  0.0470,  0.2138, -0.1447,
         0.0484, -0.1154,  0.1737, -0.1536, -0.0659,  0.0331,  0.0028, -0.1137,
        -0.1642, -0.1244,  0.1126, -0.0261,  0.0207, -0.1066, -0.1443, -0.0158,
        -0.1704, -0.0744, -0.0937, -0.0111, -0.1595, -0.0925, -0.2409, -0.1620,
        -0.0738,  0.0765, -0.0975, -0.0102, -0.0742,  0.0145,  0.0498,  0.0842,
        -0.0545,  0.0272, -0.0247, -0.0322, -0.0670, -0.0434, -0.0116,  0.0093,
        -0.2888, -0.1496,  0.0702,  0.1371,  0.0905,  0.0498, -0.0559,  0.0569,
        -0.0923, -0.2565, -0.1125, -0.0327, -0.0853,  0.1346, -0.0691,  0.0565,
        -0.0864, -0.3155,  0.0182, -0.0987, -0.1869, -0.0948, -0.0578, -0.1215,
        -0.2405, -0.0698, -0.0831, -0.1700,  0.0516, -0.0956, -0.1394, -0.1638,
        -0.0756, -0.0188, -0.1220,  0.0576, -0.0931, -0.1534, -0.0760, -0.1024,
        -0.0224, -0.0157, -0.1091, -0.1898, -0.3489,  0.0066, -0.0008, -0.1092,
        -0.2126,  0.1384, -0.2589, -0.1861, -0.1898, -0.2438, -0.1735, -0.0974,
         0.1116,  0.0082, -0.0413, -0.1102, -0.0475,  0.0903, -0.0242, -0.1464,
        -0.0609,  0.0440, -0.0698, -0.1785, -0.1937,  0.0400,  0.0518,  0.0291,
        -0.0237, -0.2067, -0.1093, -0.0723,  0.0764, -0.0608, -0.0304,  0.0026,
         0.0725,  0.0144, -0.1385, -0.1796, -0.1864, -0.0283, -0.0743,  0.1279,
         0.0806, -0.0665, -0.1150, -0.1333, -0.1723,  0.0017, -0.0921, -0.0963,
        -0.0611, -0.0687, -0.1879,  0.1293, -0.3338, -0.3510, -0.0039,  0.0162,
        -0.2148,  0.0039,  0.1118,  0.0469, -0.2428, -0.1368, -0.0812, -0.0992,
        -0.3140, -0.0950, -0.2467,  0.1609, -0.2047, -0.1273, -0.0875, -0.1277,
        -0.2504,  0.0956, -0.0445,  0.0298, -0.1901,  0.1539, -0.1458, -0.1579,
        -0.1009,  0.1838,  0.0798, -0.0433, -0.0808, -0.0580, -0.4216, -0.0373,
        -0.1366, -0.0014, -0.2278, -0.0515, -0.0872, -0.1820, -0.1058, -0.0943,
        -0.1291, -0.1471, -0.0757,  0.0189, -0.0435, -0.0252,  0.0778, -0.2574,
        -0.1267, -0.1685,  0.0287, -0.0397,  0.0789, -0.0811, -0.2187, -0.0756,
        -0.1952, -0.0356, -0.1290, -0.1553, -0.3067, -0.0752, -0.1157, -0.0445,
        -0.0020,  0.0017, -0.0229, -0.0362, -0.1294, -0.1364, -0.0693,  0.0357,
         0.0593,  0.0380, -0.0981, -0.1597,  0.0212, -0.0781, -0.1578, -0.0075,
        -0.0491, -0.1994, -0.3228, -0.0256, -0.1205,  0.0472, -0.0792,  0.0186,
        -0.2324, -0.2744, -0.2555,  0.0225, -0.1421, -0.1411, -0.0234, -0.0532,
        -0.1255, -0.1609, -0.0585,  0.0507,  0.1075,  0.0415, -0.0652, -0.0107,
        -0.1536,  0.0439, -0.1920,  0.0883, -0.0574, -0.3279, -0.1497, -0.2635,
        -0.2178, -0.0460,  0.0575, -0.0667, -0.0766, -0.0980, -0.0483, -0.0979,
        -0.3053,  0.0130, -0.0563, -0.1080,  0.0502,  0.0032, -0.0919,  0.0646,
         0.0263, -0.0618, -0.2407, -0.0799,  0.0814, -0.0578, -0.0669, -0.0273],
       device='cuda:0')

Layer: actor_backbone1.2.weight 
Shape: torch.Size([256, 512]) 
Values: tensor([[ 0.0304,  0.0493,  0.0789,  ...,  0.0632,  0.0164,  0.1726],
        [ 0.0532, -0.1999,  0.0092,  ..., -0.0180,  0.0511, -0.2668],
        [ 0.1306,  0.1006,  0.0079,  ...,  0.0772, -0.0568,  0.0080],
        ...,
        [ 0.0646,  0.1019,  0.1385,  ..., -0.2127, -0.1161,  0.0844],
        [-0.1210,  0.0583, -0.0138,  ..., -0.2092, -0.0386, -0.0492],
        [ 0.1154,  0.1690,  0.1361,  ...,  0.0735, -0.2519, -0.0308]],
       device='cuda:0')

.59it/s]
 81%|████████▏ | 156/192 [00:01<00:00, 78.04it/s]
 85%|████████▌ | 164/192 [00:02<00:00, 78.36it/s]
 90%|████████▉ | 172/192 [00:02<00:00, 78.18it/s]
 94%|█████████▍| 180/192 [00:02<00:00, 77.67it/s]
 98%|█████████▊| 188/192 [00:02<00:00, 77.49it/s]
100%|██████████| 192/192 [00:02<00:00, 79.18it/s]
/iris/u/wuqi23/anaconda3/envs/doggy/lib/python3.8/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Layer: actor_backbone1.2.bias 
Shape: torch.Size([256]) 
Values: tensor([-0.0462, -0.1441,  0.0277, -0.0184, -0.0988, -0.0486, -0.0994, -0.0608,
        -0.2105, -0.1279, -0.1207, -0.1822, -0.0427, -0.1717, -0.1404, -0.0477,
        -0.0612, -0.1855,  0.0222, -0.2877, -0.1584, -0.1317, -0.0359,  0.0498,
        -0.1100, -0.1355, -0.1654, -0.2144, -0.0494, -0.0792, -0.1551,  0.0087,
        -0.1189, -0.1196, -0.1987, -0.2672, -0.0741, -0.1399,  0.0138, -0.0944,
        -0.2825, -0.1009, -0.1109, -0.0607, -0.1639, -0.0664, -0.1575, -0.0476,
        -0.1443, -0.0803, -0.0690, -0.1211, -0.1121, -0.1490, -0.3043,  0.0373,
        -0.0768, -0.1087, -0.0959, -0.0723, -0.1892, -0.0143, -0.0884, -0.0462,
        -0.1884,  0.0235, -0.1000, -0.1937, -0.1220, -0.1211, -0.0555, -0.0843,
        -0.1650, -0.1450, -0.1772, -0.0204, -0.0411, -0.0518, -0.0863, -0.0796,
        -0.0570, -0.1111, -0.2278, -0.1772, -0.1703, -0.1116, -0.1019, -0.0551,
        -0.0898, -0.0519, -0.1447, -0.1543,  0.0081, -0.0531, -0.2637, -0.0219,
        -0.0768, -0.2120, -0.1373, -0.1200, -0.1372, -0.0123, -0.0596, -0.0356,
        -0.2190, -0.0803, -0.3062, -0.0402, -0.0718, -0.0564, -0.1307,  0.0138,
        -0.2562, -0.1478, -0.0318, -0.0421, -0.1144, -0.0410, -0.0964, -0.0985,
        -0.1368, -0.0567, -0.1236,  0.0008, -0.0242, -0.1277, -0.1358, -0.0591,
        -0.0120, -0.1369, -0.2846, -0.2055, -0.2145, -0.0468, -0.0107, -0.2586,
        -0.1932, -0.1080, -0.2110, -0.0568,  0.1033, -0.0680, -0.2939, -0.0573,
         0.0200, -0.0728, -0.1224, -0.0808, -0.1786, -0.1900, -0.0342, -0.0025,
        -0.2014, -0.1554, -0.0157, -0.0633, -0.0900, -0.2173, -0.2753, -0.1245,
        -0.1076, -0.0602, -0.0652, -0.1700, -0.0056, -0.1995, -0.1172, -0.2303,
         0.0126, -0.0893,  0.0022, -0.0211, -0.0754, -0.1768, -0.0885, -0.0279,
        -0.0641, -0.0360, -0.1027, -0.1162, -0.1126, -0.1360, -0.1286, -0.0713,
        -0.0352, -0.1211, -0.0946, -0.1020, -0.1936, -0.0356, -0.0997, -0.0907,
        -0.1414,  0.0630, -0.0889, -0.0224,  0.0032, -0.1496, -0.1598, -0.1626,
        -0.1689, -0.1878, -0.1055, -0.1582, -0.1701,  0.0175, -0.0565, -0.1244,
        -0.0855, -0.2199, -0.0453, -0.0521, -0.1059, -0.1009, -0.1446,  0.0417,
        -0.0984,  0.0155,  0.0303, -0.0233, -0.1955, -0.0160,  0.0010, -0.1330,
        -0.0277, -0.2380, -0.1674, -0.0347, -0.1022,  0.0089, -0.0989, -0.0497,
        -0.0662, -0.0651, -0.0564, -0.0021, -0.1263, -0.1053, -0.1512, -0.0218,
        -0.1150, -0.0715, -0.0512, -0.1694, -0.1767,  0.0692, -0.1027, -0.1160,
        -0.1090, -0.2191, -0.0842, -0.1369, -0.1643, -0.1352, -0.1448,  0.0036],
       device='cuda:0')

Layer: actor_backbone1.4.weight 
Shape: torch.Size([128, 256]) 
Values: tensor([[ 0.0167, -0.0151, -0.0713,  ...,  0.0450, -0.0996,  0.0577],
        [ 0.0042,  0.0456,  0.0622,  ...,  0.0279,  0.0371, -0.0496],
        [-0.1269,  0.0588,  0.0906,  ...,  0.0368, -0.0244, -0.1746],
        ...,
        [-0.1612,  0.1084, -0.0517,  ...,  0.0414, -0.0280, -0.0451],
        [-0.0329, -0.0250,  0.0696,  ...,  0.1729, -0.0005,  0.0487],
        [ 0.0464, -0.2221, -0.0422,  ...,  0.0253, -0.0627,  0.0325]],
       device='cuda:0')

Layer: actor_backbone1.4.bias 
Shape: torch.Size([128]) 
Values: tensor([ 2.2986e-04,  2.2220e-01, -2.5422e-02, -9.9098e-02, -3.0029e-01,
        -1.3345e-01,  4.7790e-03, -1.2517e-01, -3.5444e-02,  1.9761e-01,
        -2.0700e-01, -3.3633e-01, -1.3872e-01, -1.3760e-01,  5.9403e-02,
        -2.8170e-02, -3.7747e-02,  3.3679e-02,  2.4282e-02,  7.3124e-02,
        -7.9319e-02, -9.3145e-03,  7.8355e-02, -1.1755e-01,  4.5793e-03,
        -1.1286e-01, -3.2321e-03,  1.8580e-01, -3.6078e-02, -2.7283e-02,
        -1.1913e-01, -9.7922e-02, -7.4746e-02,  1.3565e-02,  4.8352e-02,
        -3.1039e-02,  5.8673e-03, -2.3395e-01, -5.2095e-02, -2.6013e-01,
         1.5796e-01,  1.4786e-02, -3.0791e-01, -2.9857e-02, -2.7114e-01,
         3.2104e-02, -8.5572e-02, -3.1311e-02,  1.2201e-01,  7.0421e-02,
        -3.0200e-01, -1.0189e-01, -7.4942e-03,  7.1164e-03, -1.4171e-01,
        -9.7476e-02,  1.3912e-01, -2.3363e-01, -3.8784e-02,  1.0623e-01,
         1.8074e-01, -1.6193e-01,  1.2634e-01, -3.2072e-02, -1.3843e-01,
        -5.7619e-02, -2.7158e-02, -8.8406e-02, -1.7048e-01, -1.3514e-01,
        -1.7725e-01,  7.3903e-02, -4.4713e-01, -2.3963e-01, -2.4764e-01,
         1.8692e-01, -1.8618e-01, -1.9706e-02, -8.0805e-02, -1.3096e-01,
        -3.4321e-02,  6.5846e-02,  5.5089e-02, -7.6971e-02,  9.9400e-02,
         1.5945e-01, -1.4124e-01, -1.0864e-01,  1.0450e-01,  3.8879e-02,
        -1.1593e-01, -6.8412e-02, -6.4640e-02, -1.7205e-01, -5.2586e-02,
        -5.4723e-02, -4.8933e-02,  2.7956e-01, -1.9981e-01,  6.2744e-02,
        -4.0527e-02, -1.1633e-01, -1.3543e-01, -3.8435e-03, -8.8647e-02,
        -1.6301e-01, -6.1535e-02, -1.5528e-01, -8.3930e-02, -3.9627e-01,
         1.7690e-02,  3.2986e-02, -1.1557e-01, -1.4083e-02, -4.8685e-03,
        -6.3829e-02,  3.1164e-03,  4.8622e-02, -1.2818e-01,  5.0175e-02,
        -2.9073e-01, -8.6358e-02,  1.0931e-01,  2.3394e-02,  1.3539e-01,
        -1.8670e-02, -2.8068e-01,  7.5963e-02], device='cuda:0')

Layer: actor_backbone1.6.weight 
Shape: torch.Size([13, 128]) 
Values: tensor([[ 8.3851e-03, -8.2046e-02,  2.6113e-02,  ..., -1.6500e-02,
         -2.1886e-03, -3.4074e-02],
        [-1.4386e-02, -8.1937e-02,  3.8539e-04,  ..., -5.9808e-02,
          6.7008e-03,  2.7832e-02],
        [-1.2808e-01,  1.3689e-01,  1.0685e-01,  ...,  2.9708e-02,
         -5.0568e-02, -1.0234e-01],
        ...,
        [ 8.3530e-02, -3.7829e-02, -1.8947e-02,  ...,  4.7277e-02,
         -5.1102e-02,  7.7236e-02],
        [ 9.7742e-02,  2.6714e-01,  1.3720e-01,  ...,  3.9324e-01,
         -1.9056e-01, -7.2930e-01],
        [-1.2300e-01, -5.8594e-01, -5.2344e-01,  ..., -3.9395e-01,
         -1.0367e-01,  1.6635e-01]], device='cuda:0')

Layer: actor_backbone1.6.bias 
Shape: torch.Size([13]) 
Values: tensor([-0.1164,  0.2060,  0.2416,  0.0385,  0.0877,  0.1320, -0.0681,  0.0975,
         0.5164, -0.0464,  0.0551,  0.3352, -0.5341], device='cuda:0')